{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b758d6a5",
   "metadata": {},
   "source": [
    "### 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba39a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "x+y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f202f",
   "metadata": {},
   "source": [
    "### 向量->矩阵->更多维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006330e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0364c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acc97d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891df4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建矩阵\n",
    "A = torch.arange(20).reshape(5,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473e91f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵的转置\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f760f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 0, 4],\n",
      "        [3, 4, 5]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# 对称矩阵 B == B.T\n",
    "B = torch.tensor([[1,2,3], [2,0,4], [3,4,5]])\n",
    "print(B)\n",
    "print(B == B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8b31ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 就像向量是标量的推广，矩阵是向量的推广一样，可以构建具有更多轴的数据结构\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559de509",
   "metadata": {},
   "source": [
    "### 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "731b83e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 相加\n",
    "A = torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
    "B = A.clone() # 通过分配新内存，将A的副本分配给B\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a65ecc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]),\n",
       " tensor([[  0.,   1.,   4.,   9.],\n",
       "         [ 16.,  25.,  36.,  49.],\n",
       "         [ 64.,  81., 100., 121.]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 哈达玛积 (按元素相乘)\n",
    "A,B,A*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03297f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[[ 2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9],\n",
       "          [10, 11, 12, 13]],\n",
       " \n",
       "         [[14, 15, 16, 17],\n",
       "          [18, 19, 20, 21],\n",
       "          [22, 23, 24, 25]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量和标量相乘\n",
    "a = 2\n",
    "X = torch.arange(24).reshape(2,3,4)\n",
    "X, a + X, (a*X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "613079fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 4]), tensor(780.))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算元素的和\n",
    "# 不论什么形状的张量，其元素的和永远是一个标量\n",
    "A = torch.arange(20*2, dtype=torch.float32).reshape(2, 5, 4)\n",
    "A.shape, A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf7fa34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.]],\n",
      "\n",
      "        [[20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.],\n",
      "         [32., 33., 34., 35.],\n",
      "         [36., 37., 38., 39.]]])\n",
      "tensor([[20., 22., 24., 26.],\n",
      "        [28., 30., 32., 34.],\n",
      "        [36., 38., 40., 42.],\n",
      "        [44., 46., 48., 50.],\n",
      "        [52., 54., 56., 58.]]) torch.Size([5, 4])\n",
      "tensor([[ 40.,  45.,  50.,  55.],\n",
      "        [140., 145., 150., 155.]]) torch.Size([2, 4])\n",
      "tensor([[  6.,  22.,  38.,  54.,  70.],\n",
      "        [ 86., 102., 118., 134., 150.]]) torch.Size([2, 5])\n",
      "tensor([180., 190., 200., 210.]) torch.Size([4])\n",
      "tensor([ 92., 124., 156., 188., 220.]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# 指定张量的轴 进行 求和汇总\n",
    "# tips：此处容易混淆\n",
    "# 根据哪个维度求和，得到的结果就是将原shape中求和维度去掉后 剩下的维度\n",
    "# 如shape:[2,5,4]，根据axis=0,2求和，得到shape:[5]\n",
    "\n",
    "print(A)\n",
    "\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "print(A_sum_axis0, A_sum_axis0.shape)\n",
    "\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "print(A_sum_axis1, A_sum_axis1.shape)\n",
    "\n",
    "A_sum_axis2 = A.sum(axis=2)\n",
    "print(A_sum_axis2, A_sum_axis2.shape)\n",
    "\n",
    "A_sum_axis01 = A.sum(axis=[0,1])\n",
    "print(A_sum_axis01, A_sum_axis01.shape)\n",
    "\n",
    "A_sum_axis02 = A.sum(axis=[0,2])\n",
    "print(A_sum_axis02, A_sum_axis02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f9e6b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.]],\n",
      "\n",
      "        [[20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.],\n",
      "         [32., 33., 34., 35.],\n",
      "         [36., 37., 38., 39.]]])\n",
      "tensor(19.5000) tensor(19.5000) torch.Size([2, 5, 4])\n",
      "tensor([[10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.],\n",
      "        [18., 19., 20., 21.],\n",
      "        [22., 23., 24., 25.],\n",
      "        [26., 27., 28., 29.]]) tensor([[10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.],\n",
      "        [18., 19., 20., 21.],\n",
      "        [22., 23., 24., 25.],\n",
      "        [26., 27., 28., 29.]])\n"
     ]
    }
   ],
   "source": [
    "# 求平均值（可按维度）\n",
    "print(A)\n",
    "\n",
    "print(A.mean(), A.sum()/A.numel(), A.shape)\n",
    "\n",
    "print(A.mean(axis=0), A.sum(axis=0)/A.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e43a63ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 40.,  45.,  50.,  55.]],\n",
       "\n",
       "        [[140., 145., 150., 155.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算总和或均值时保持轴数不变\n",
    "# keepdims即是保持原来的轴数不变，将指定的轴数变为1\n",
    "# 如shape[2,5,4],根据轴数axis=1求和，则得到维度数目依然为3，维度为[2,1,4]\n",
    "\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03924dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.]],\n",
      "\n",
      "        [[20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.],\n",
      "         [32., 33., 34., 35.],\n",
      "         [36., 37., 38., 39.]]]) tensor([[[ 40.,  45.,  50.,  55.]],\n",
      "\n",
      "        [[140., 145., 150., 155.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0222, 0.0400, 0.0545],\n",
       "         [0.1000, 0.1111, 0.1200, 0.1273],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.3000, 0.2889, 0.2800, 0.2727],\n",
       "         [0.4000, 0.3778, 0.3600, 0.3455]],\n",
       "\n",
       "        [[0.1429, 0.1448, 0.1467, 0.1484],\n",
       "         [0.1714, 0.1724, 0.1733, 0.1742],\n",
       "         [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "         [0.2286, 0.2276, 0.2267, 0.2258],\n",
       "         [0.2571, 0.2552, 0.2533, 0.2516]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过广播A除以sum_A\n",
    "print(A, sum_A)\n",
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fc2b493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19.]],\n",
      "\n",
      "        [[20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.],\n",
      "         [32., 33., 34., 35.],\n",
      "         [36., 37., 38., 39.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]],\n",
       "\n",
       "        [[20., 22., 24., 26.],\n",
       "         [28., 30., 32., 34.],\n",
       "         [36., 38., 40., 42.],\n",
       "         [44., 46., 48., 50.],\n",
       "         [52., 54., 56., 58.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 某个轴的累积求和\n",
    "print(A)\n",
    "A.cumsum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "931c578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 点积：是标量；表示相同位置上的元素相乘 再求和\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "y = torch.ones(4, dtype=torch.float32)\n",
    "x, y, torch.dot(x, y)\n",
    "\n",
    "# 等价于sum(x*y)\n",
    "torch.sum(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f036c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]]) torch.Size([5, 4])\n",
      "tensor([0., 1., 2., 3.]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 14.,  38.,  62.,  86., 110.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵*向量\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "A = torch.arange(20, dtype=torch.float32).reshape(5,4)\n",
    "print(A, A.shape)\n",
    "print(x, x.shape)\n",
    "torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca993155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4]) torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.],\n",
       "        [54., 54., 54.],\n",
       "        [70., 70., 70.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 矩阵*矩阵\n",
    "B = torch.ones(4, 3)\n",
    "print(A.shape, B.shape)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9ffdba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 范数：向量或矩阵的长度\n",
    "\n",
    "# L2范数：向量元素平方和的平方根\n",
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u) # 标量\n",
    "\n",
    "# L1范数：向量元素的绝对值之和\n",
    "torch.abs(u).sum()\n",
    "\n",
    "# 矩阵的F范数：矩阵元素的平方和的平方根\n",
    "A = torch.ones((4, 9))\n",
    "torch.norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8427b87",
   "metadata": {},
   "source": [
    "### 轴数详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16764b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1.]]]),\n",
       " torch.Size([2, 5, 4]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones((2,5,4))\n",
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5f17d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape为空，表示为标量\n",
    "a.sum().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cedebb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 5., 5., 5.],\n",
       "         [5., 5., 5., 5.]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.sum(axis=1)\n",
    "b, b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea44d8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5., 5., 5., 5.]],\n",
       " \n",
       "         [[5., 5., 5., 5.]]]),\n",
       " torch.Size([2, 1, 4]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keepdims 保留维度数目，将axis指定的维度值变为1\n",
    "c = a.sum(axis=1, keepdims=True)\n",
    "c, c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9359e6",
   "metadata": {},
   "source": [
    "## QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d933588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q:torch不区分行向量和列向量吗？\n",
    "# A:torch中如果是一维向量的话 一定是行向量；如果要区分行列，可以用矩阵表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "62061ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q:张量的概念 机器学习里和数学中 有哪些区别？\n",
    "# A:机器学习中的张量可以理解成数组，和数学中的张量不是一个概念"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
